epoch,learning_rate,step,train_loss
0,1.8576437610384744e-10,49,4.903866767883301
0,3.7531988628103363e-10,99,5.478334426879883
0,5.648753687026442e-10,149,1.9792035818099976
0,7.544308511242548e-10,199,2.0122005939483643
0,9.439863335458654e-10,249,2.8132035732269287
0,1.133541815967476e-09,299,2.3494298458099365
0,1.3230972983890865e-09,349,2.4421427249908447
0,1.512652780810697e-09,399,2.698676824569702
0,1.7022083742546101e-09,449,1.2242345809936523
0,1.8917638566762207e-09,499,3.8097596168518066
0,2.0813193390978313e-09,549,4.909791946411133
0,2.270874821519442e-09,599,0.017198828980326653
0,2.4604303039410524e-09,649,3.839322328567505
0,2.649985786362663e-09,699,1.210640549659729
0,2.8395412687842736e-09,749,0.14835616946220398
0,3.029096751205884e-09,799,7.341363906860352
0,3.2186522336274948e-09,849,2.672433853149414
0,3.4082077160491053e-09,899,2.1886885166168213
0,3.597763198470716e-09,949,2.5891196727752686
0,3.787318902936931e-09,999,7.789344787597656
0,3.976874385358542e-09,1049,1.6005058288574219
0,4.1664298677801526e-09,1099,0.12219151854515076
0,4.355985350201763e-09,1149,0.7736223936080933
0,4.545540832623374e-09,1199,0.04215103015303612
0,4.735096315044984e-09,1249,6.843769550323486
0,4.924651797466595e-09,1299,2.589918851852417
0,5.1142072798882054e-09,1349,3.352710008621216
0,5.303762762309816e-09,1399,1.162868618965149
0,5.493318244731427e-09,1449,3.264986753463745
